<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <title>Why 3D May Emerge as a Transformative Modality - Feiran Wang</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="icon" href="../image/me/iconf2.png" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="../stylesheet.css">
    <style>
      .blog-container {
        max-width: 850px;
        margin: 0 auto;
        padding: 50px 20px;
      }

      .blog-header {
        margin-bottom: 50px;
        border-bottom: 1px solid #ddd;
        padding-bottom: 30px;
      }

      .blog-title {
        font-size: 38px;
        font-weight: 700;
        margin-bottom: 18px;
        color: #000;
        font-family: 'Lato', Verdana, Helvetica, sans-serif;
        line-height: 1.3;
      }

      .blog-meta {
        font-size: 16px;
        color: #888;
        margin-top: 10px;
      }

      .blog-content {
        font-size: 18px;
        line-height: 1.8;
        color: #333;
      }

      .blog-content h2 {
        font-size: 30px;
        font-weight: 600;
        margin-top: 45px;
        margin-bottom: 22px;
        color: #000;
      }

      .blog-content h3 {
        font-size: 22px;
        font-weight: 500;
        margin-top: 32px;
        margin-bottom: 18px;
        color: #000;
      }

      .blog-content p {
        margin-bottom: 20px;
      }

      .con {
        font-size: 18px;
        line-height: 1.8;
        color: #333;
        margin-bottom: 20px;
      }

      .blog-content ul, .blog-content ol {
        margin-bottom: 20px;
        padding-left: 32px;
      }

      .blog-content li {
        margin-bottom: 12px;
        line-height: 1.8;
      }

      .blog-content code {
        background-color: #f8f8f8;
        padding: 3px 6px;
        font-family: 'Courier New', monospace;
        font-size: 16px;
      }

      .blog-content pre {
        background-color: #f8f8f8;
        padding: 18px;
        overflow-x: auto;
        margin-bottom: 22px;
        border: 1px solid #e0e0e0;
      }

      .blog-content pre code {
        background-color: transparent;
        padding: 0;
        font-size: 15px;
      }

      .blog-content blockquote {
        border-left: 4px solid #1772d0;
        padding-left: 24px;
        margin: 25px 0;
        color: #444;
        font-style: italic;
        font-size: 18px;
      }

      .blog-content img {
        max-width: 100%;
        height: auto;
        display: block;
        margin: 30px auto;
      }

      .references {
        margin-top: 60px;
        padding-top: 30px;
        border-top: 2px solid #ddd;
      }

      .references h3 {
        font-size: 24px;
        font-weight: 600;
        margin-bottom: 20px;
        color: #000;
      }

      .references ol {
        padding-left: 20px;
        margin: 0;
      }

      .references li {
        font-size: 15px;
        line-height: 1.7;
        color: #444;
        margin-bottom: 12px;
      }

      .author-info {
        margin-top: 60px;
        padding: 25px;
        background-color: #f9f9f9;
        border-left: 3px solid #1772d0;
      }

      .author-info h3 {
        font-size: 18px;
        font-weight: 400;
        margin-top: 0;
        margin-bottom: 12px;
        color: #000;
      }

      .author-info p {
        font-size: 15px;
        line-height: 1.6;
        color: #555;
        margin-bottom: 12px;
      }

      .author-info a {
        color: #1772d0;
        text-decoration: none;
        font-weight: 500;
      }

      .author-info a:hover {
        color: #f09228;
      }

      .blog-footer {
        margin-top: 40px;
        padding-top: 20px;
        border-top: 1px solid #ddd;
        text-align: center;
        font-size: 14px;
        color: #888;
      }

      .lang-switch {
        position: fixed;
        top: 30px;
        right: 30px;
        z-index: 1000;
      }

      .lang-switch a {
        display: inline-block;
        padding: 0;
        background-color: transparent;
        text-decoration: none;
        transition: opacity 0.3s;
      }

      .lang-switch a:hover {
        opacity: 0.7;
      }
    </style>
  </head>

  <body>
    <!-- <div class="lang-switch">
      <a href="3D_scene_11_22_25_cn.html">中文</a>
    </div> -->
    <div class="lang-switch">
  <a href="3D_scene_11_22_25_cn.html">
    <img src="translate1.svg" alt="中文" style="width: 40px; height: 40px;">
  </a>
</div>

    <div class="blog-container">
      <div class="blog-header">
        <h1 class="blog-title">Why 3D Scenes May Emerge as a Transformative Modality in Human Communication</h1>
<div class="blog-meta">
  <span>November 2025</span>
  <span style="margin:0 12px;color:#ccc">|</span>
  <span>Feiran Wang</span>
   <span style="margin:0 12px;color:#ccc">|</span>
 <a href="../index.html" style="color:#1772d0;text-decoration:none;font-size:16px;">Homepage</a>
</div>
      </div>

      <div class="blog-content">
        <!-- Your content starts here -->

        <h2>The Evolution of Information Dimensions</h2>

        <p class="con">
          From ancient postal systems to the early World Wide Web, human beings have predominantly shared and connected through one-dimensional information: text and voice. With the advancement of communication technologies, information modalities gradually expanded into two dimensions, first with images and later with videos. Today, 1D and 2D modalities coexist in our modern life, enabling increasingly instant communication and underpinning much of contemporary society.
        </p>

        <h2>The Appeal of Immersive Information</h2>

        <p class="con">
          Higher-dimensional information formats appear to resonate with human perception, though not simply because they contain more raw data. Rather, they may align more closely with how we naturally experience the world, potentially triggering stronger emotional and cognitive responses. A photograph of a battlefield can convey the immediacy of conflict more viscerally than text descriptions; a video of a child playing might evoke joy more spontaneously than written accounts. This suggests that visual media can communicate certain types of information, particularly emotional and contextual, more efficiently than text alone.
        </p>

        <p class="con">
          3D scenes represent a further step in this progression. By immersing individuals in spatial environments that approximate physical presence, they offer the potential for more intuitive understanding and richer contextual information transfer, though the extent of this advantage likely varies significantly across different use cases.
        </p>

        <h2>The Trade-offs Between Modalities</h2>

        <p class="con">
          It's important to recognize that different modalities (text, images, video, and 3D scenes) each have distinct strengths rather than existing in a simple hierarchy. Lower-dimensional formats excel at logical argumentation and precise communication, while requiring less bandwidth and cognitive load. Higher-dimensional formats can convey experiential and emotional content more readily, as suggested by the adage "a picture is worth a thousand words." One might extend this to suggest that experiencing a 3D scene could communicate spatial and contextual information more effectively than multiple videos.
        </p>

        <blockquote>
          The emergence of 3D as a more accessible modality would likely complement rather than replace existing formats, with each medium supporting the others to convey facts, perspectives, and experiences.
        </blockquote>

        <p class="con">
          However, higher-dimensional information comes with trade-offs: increased data requirements, potential for information overload, and sometimes weaker capacity for structured logical expression. In practice, effective communication often involves thoughtful combinations of text, images, video, and increasingly, 3D elements.
        </p>

        <h2>The Missing Piece: Accessible Infrastructure</h2>

        <p class="con">
          While 3D scene technology has advanced significantly, it has not yet achieved the kind of societal penetration seen with the World Wide Web or, more recently, large language models. A key factor appears to be the lack of a ubiquitous, user-friendly delivery platform.
        </p>

        <p class="con">
          Historical patterns offer some perspective: early text-based communication required telegraph infrastructure and later the internet; widespread image and video sharing became practical only with modern smartphones and high-bandwidth networks. Currently, 3D content creation and consumption remain largely confined to specialized domains such as gaming, professional visualization, and research. What's still missing is a device that seamlessly integrates into everyday life for the general public.
        </p>

        <p class="con">
          Despite substantial investment from major technology companies and startups in AR/VR headsets and 3D imaging systems over the past two decades, no product has yet achieved the trifecta of comfort, affordability, and broad utility. Many devices generate initial excitement but fail to establish sustained usage patterns, suggesting that significant technical or design challenges remain.
        </p>

        <blockquote>
          Technology adoption often follows nonlinear trajectories. The iPhone's introduction in 2007 catalyzed rapid mainstream adoption of mobile internet and visual media, features that had existed in various forms for years but hadn't found the right platform.
        </blockquote>

        <p class="con">
          A similar inflection point for 3D technology is plausible, though its timing and specific form remain to be determined.
        </p>

        <h2>Accelerating Progress in 3D Research</h2>

        <p class="con">
          The research landscape for 3D technologies has evolved remarkably over the past decade, driven by improvements in computing hardware, depth sensors, and machine learning algorithms.
        </p>

        <p class="con">
          Traditional geometry-based methods like COLMAP [1] and multi-view stereo provided important foundations. Microsoft's Kinect Fusion [2] demonstrated consumer-grade RGBD reconstruction. The integration of learning-based approaches, such as MVSNet [3], marked a significant methodological shift. More recently, Neural Radiance Fields (NeRF) [4] and 3D Gaussian Splatting [5] have enabled novel view synthesis with impressive visual quality, while transformer architectures have shown promise across multiple 3D tasks.
        </p>

        <p class="con">
          The emergence of vision foundation models like DUSt3R [6], VGGT [7] and others represents another potential step change, dramatically improving the quality and speed of 2D-to-3D conversion in certain scenarios. Current research increasingly focuses on multimodal integration, incorporating language models and pursuing "world models" that combine multiple sensing and reasoning capabilities.
        </p>

        <p class="con">
          These developments suggest that many technical barriers to high-quality 3D reconstruction and rendering are diminishing, though challenges around efficiency, generalization, and real-time performance remain active research areas.
        </p>

        <h2>A Future Closer Than It Appears</h2>

        <p class="con">
          3D scenes offer a distinctive capacity for conveying spatial presence and contextual richness. Humans' innate spatial reasoning abilities suggest a natural affinity for well-designed 3D interfaces. The practical advantages of this match between human perception and 3D content are increasingly being demonstrated across various applications.
        </p>

        <p class="con">
          The foundations have developed substantially: hardware capabilities continue to advance, algorithmic approaches are maturing rapidly, and theoretical understanding deepens. Whether 3D modalities will achieve mainstream adoption comparable to 2D visual media depends on multiple factors: continued technical progress, the emergence of compelling use cases, development of accessible platforms, and ultimately user behavior and preferences.
        </p>

        <blockquote>
          The trajectory suggests we may be approaching an inflection point. The pace of capability development in both research and industry has accelerated markedly.
        </blockquote>

        <p class="con">
          While the specific form factor and timeline remain open questions, the convergence of multiple technological threads points toward a nearer-term future than conventional wisdom might suggest. This is a moment of genuine possibility, one where the pieces are rapidly coming together. The question is perhaps less about whether 3D communication will become mainstream, and more about recognizing when that transition begins to unfold.
        </p>

        <!-- Your content ends here -->
      </div>

            <!-- Author Info Section -->
      <div class="author-info">
        <h3>About the Author</h3>
        <p>
          <strong>Feiran Wang</strong> is a PhD student in Computer Vision,
          specializing in 3D reconstruction, vision foundation models, medical imaging, and generative AI.
          His research focuses on bridging the physical and digital world, creating real-world impact.
        </p>
        <p>
          <a href="../index.html">Visit my homepage</a> to learn more about my research and publications.
        </p>
      </div>

      <!-- References Section -->
      <div class="references">
        <h3>References</h3>
        <ol>
          <li>Schönberger, Johannes Lutz, and Jan-Michael Frahm. "Structure-from-Motion Revisited." <em>Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2016.</li>
          <li>Newcombe, Richard A., et al. "Kinectfusion: Real-time dense surface mapping and tracking." <em>2011 10th IEEE international symposium on mixed and augmented reality</em>. IEEE, 2011.</li>
          <li>Yao, Yao, et al. "Mvsnet: Depth inference for unstructured multi-view stereo." <em>Proceedings of the European conference on computer vision (ECCV)</em>. 2018.</li>
          <li>Mildenhall, Ben, et al. "Nerf: Representing scenes as neural radiance fields for view synthesis." <em>Communications of the ACM</em> 65.1 (2021): 99-106.</li>
          <li>Kerbl, Bernhard, et al. "3D Gaussian splatting for real-time radiance field rendering." <em>ACM Trans. Graph.</em> 42.4 (2023): 139-1.</li>
          <li>Wang, Shuzhe, et al. "Dust3r: Geometric 3d vision made easy." <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 2024.</li>
          <li>Wang, Jianyuan, et al. "Vggt: Visual geometry grounded transformer." <em>Proceedings of the Computer Vision and Pattern Recognition Conference</em>. 2025.</li>
        </ol>
      </div>



      <div class="blog-footer">
        <p>&copy; 2025 Feiran Wang</p>
      </div>
    </div>
  </body>

</html>