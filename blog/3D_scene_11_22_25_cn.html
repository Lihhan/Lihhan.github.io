<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <title>Why 3D May Emerge as a Transformative Modality - Feiran Wang</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="icon" href="../image/me/iconf2.png" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="../stylesheet.css">
    <style>
      .blog-container {
        max-width: 850px;
        margin: 0 auto;
        padding: 50px 20px;
      }

      .blog-header {
        margin-bottom: 50px;
        border-bottom: 1px solid #ddd;
        padding-bottom: 30px;
      }

      .blog-title {
        font-size: 38px;
        font-weight: 700;
        margin-bottom: 18px;
        color: #000;
        font-family: 'Lato', Verdana, Helvetica, sans-serif;
        line-height: 1.3;
      }

      .blog-meta {
        font-size: 16px;
        color: #888;
        margin-top: 10px;
      }

      .blog-content {
        font-size: 18px;
        line-height: 1.8;
        color: #333;
      }

      .blog-content h2 {
        font-size: 30px;
        font-weight: 600;
        margin-top: 45px;
        margin-bottom: 22px;
        color: #000;
      }

      .blog-content h3 {
        font-size: 22px;
        font-weight: 500;
        margin-top: 32px;
        margin-bottom: 18px;
        color: #000;
      }

      .blog-content p {
        margin-bottom: 20px;
      }

      .con {
        font-size: 18px;
        line-height: 1.8;
        color: #333;
        margin-bottom: 20px;
      }

      .blog-content ul, .blog-content ol {
        margin-bottom: 20px;
        padding-left: 32px;
      }

      .blog-content li {
        margin-bottom: 12px;
        line-height: 1.8;
      }

      .blog-content code {
        background-color: #f8f8f8;
        padding: 3px 6px;
        font-family: 'Courier New', monospace;
        font-size: 16px;
      }

      .blog-content pre {
        background-color: #f8f8f8;
        padding: 18px;
        overflow-x: auto;
        margin-bottom: 22px;
        border: 1px solid #e0e0e0;
      }

      .blog-content pre code {
        background-color: transparent;
        padding: 0;
        font-size: 15px;
      }

      .blog-content blockquote {
        border-left: 4px solid #1772d0;
        padding-left: 24px;
        margin: 25px 0;
        color: #444;
        font-style: italic;
        font-size: 18px;
      }

      .blog-content img {
        max-width: 100%;
        height: auto;
        display: block;
        margin: 30px auto;
      }

      .references {
        margin-top: 60px;
        padding-top: 30px;
        border-top: 2px solid #ddd;
      }

      .references h3 {
        font-size: 24px;
        font-weight: 600;
        margin-bottom: 20px;
        color: #000;
      }

      .references ol {
        padding-left: 20px;
        margin: 0;
      }

      .references li {
        font-size: 15px;
        line-height: 1.7;
        color: #444;
        margin-bottom: 12px;
      }

      .author-info {
        margin-top: 60px;
        padding: 25px;
        background-color: #f9f9f9;
        border-left: 3px solid #1772d0;
      }

      .author-info h3 {
        font-size: 18px;
        font-weight: 400;
        margin-top: 0;
        margin-bottom: 12px;
        color: #000;
      }

      .author-info p {
        font-size: 15px;
        line-height: 1.6;
        color: #555;
        margin-bottom: 12px;
      }

      .author-info a {
        color: #1772d0;
        text-decoration: none;
        font-weight: 500;
      }

      .author-info a:hover {
        color: #f09228;
      }

      .blog-footer {
        margin-top: 40px;
        padding-top: 20px;
        border-top: 1px solid #ddd;
        text-align: center;
        font-size: 14px;
        color: #888;
      }

      .lang-switch {
        position: fixed;
        top: 30px;
        right: 30px;
        z-index: 1000;
      }

      .lang-switch a {
        display: inline-block;
        padding: 0;
        background-color: transparent;
        text-decoration: none;
        transition: opacity 0.3s;
      }

      .lang-switch a:hover {
        opacity: 0.7;
      }
    </style>
  </head>

  <body>
    <!-- <div class="lang-switch">
      <a href="3D_scene_11_22_25.html">English</a>
    </div> -->
    <div class="lang-switch">
  <a href="3D_scene_11_22_25.html">
    <img src="translate1.svg" alt="English" style="width: 40px; height: 40px;">
  </a>
</div>

    <div class="blog-container">
      <div class="blog-header">
        <h1 class="blog-title">为什么3D场景可能成为人类交流的变革性模态</h1>
<div class="blog-meta">
  <span>2025年11月</span>
  <span style="margin:0 12px;color:#ccc">|</span>
  <span>斐然</span>
</div>
      </div>

      <div class="blog-content">
        <!-- Your content starts here -->

        <h2>信息维度的演进</h2>

        <p class="con">
          从古代邮政系统到早期的万维网,人类一直主要依靠一维信息进行交流：文字与声音。随着通信技术的发展,信息模态逐渐向二维扩展,先是图像,后来是视频。如今,一维和二维模态在现代生活中共存,让即时通信成为可能,也构成了当代社会运转的基础。
        </p>

        <h2>沉浸式信息的独特魅力</h2>

        <p class="con">
          为什么更高维度的信息形式能与人类感知产生共鸣？这并非简单因为它们承载了更多原始数据,而是因为它们更贴近我们体验世界的自然方式,能够触发更强烈的情感和认知反应。战场的照片比文字描述更能让人感受到战争的残酷；孩童玩耍的视频比文字记录更能自然地唤起喜悦。这说明视觉媒体在传递某些信息——尤其是情感和情境信息时,比单纯的文字更加高效。
        </p>

        <p class="con">
          3D场景进一步推进了这一趋势。它将人们沉浸在接近真实临场的空间环境中,让理解变得更加直观,情境信息的传递也更加丰富,虽然这种优势在不同应用场景中的表现可能差异很大。
        </p>

        <h2>不同模态的利弊权衡</h2>

        <p class="con">
          我们需要认识到,文字、图像、视频和3D场景这些不同模态各有所长,并不存在简单的高下之分。低维格式擅长逻辑论证和精确表达,所需的带宽和认知负荷也更小。高维格式则更容易传达体验感和情感,正如那句"一图胜千言"。我们可以进一步推想：身临其境地体验一个3D场景,在传达空间和情境信息方面,或许比看多个视频更有效。
        </p>

        <blockquote>
          3D作为一种更易理解的模态,很可能不会取代现有格式,而是与其他媒介相互补充,共同传达事实、观点和体验。
        </blockquote>

        <p class="con">
          但高维信息也有代价：需要更多数据、容易造成信息过载,在结构化逻辑表达上有时也不如低维格式。实际应用中,有效的沟通往往需要文字、图像、视频以及越来越多的3D元素互相配合。
        </p>

        <h2>缺失的关键：触手可及的基础设施</h2>

        <p class="con">
          尽管3D场景技术已经取得了长足进步,但还远未达到万维网或近期大语言模型那样的社会普及度。关键问题似乎在于：我们还缺少一个无处不在、容易上手的传播平台。
        </p>

        <p class="con">
          回顾历史可以看到一些规律：早期文本通信依赖电报基础设施,后来是互联网；图像和视频的广泛分享,则要等到智能手机和高带宽网络普及之后。目前,3D内容的创作和消费基本还局限在游戏、专业可视化和研究等专业领域。我们缺少的,是一个能真正融入普通人日常生活的载体。
        </p>

        <p class="con">
          过去二十年里,从科技巨头到初创公司,在AR/VR头显和3D成像系统上投入了大量资金,但还没有哪个产品能同时做到舒适、实惠和广泛实用。很多设备刚上市时热度很高,但很快就成了吃灰的玩具,无法维持用户的持续使用,这说明技术或设计上仍存在不小的挑战。
        </p>

        <blockquote>
          技术普及往往不是线性的。2007年iPhone的出现,迅速推动了移动互联网和视觉媒体的主流化,而这些功能其实早就以各种形式存在,只是一直没找到合适的平台。
        </blockquote>

        <p class="con">
          3D技术也可能出现类似的转折点,只是具体的时间和形式还有待观察。
        </p>

        <h2>3D研究的加速突破</h2>

        <p class="con">
          过去十年,得益于计算硬件、深度传感器和机器学习算法的进步,3D技术的研究面貌发生了巨大变化。
        </p>

        <p class="con">
          传统的几何方法,比如多视图立体(SFM)和COLMAP[1] 打下了重要基础。微软的Kinect Fusion [2] 展示了消费级RGBD重建的可能性。基于学习方法的引入,如MVSNet [3],标志着方法论的重要转变。近年来,神经辐射场（NeRF）[4] 和3D高斯溅射 [5] 实现了视觉效果出色的新视图合成,而Transformer架构在多个3D任务中也展现出巨大潜力。
        </p>

        <p class="con">
          DUSt3R [6]、VGGT [7] 等视觉基础模型的出现,可能带来又一次跃升,在某些场景下大幅提升了2D到3D转换的质量和速度。当前研究越来越聚焦于多模态融合,将语言模型整合进来,并探索结合多种感知和推理能力的"世界模型"。
        </p>

        <p class="con">
          这些进展说明,高质量3D重建和渲染的许多技术障碍正在消除,虽然在效率、泛化能力和实时性能方面仍有不少挑战有待解决。
        </p>

        <h2>未来或许近在眼前</h2>

        <p class="con">
          3D场景在传达空间临场感和情境丰富性方面有着独特的优势。人类天生的空间推理能力,让我们对设计良好的3D界面有着天然的亲近感。这种人类感知与3D内容之间的契合,其实际价值正在各种应用中得到越来越多的验证。
        </p>

        <p class="con">
          基础条件已经日趋成熟：硬件能力持续增强,算法方法快速迭代,理论认识不断深化。3D模态能否像2D视觉媒体那样被主流接受,取决于多方面因素：技术的持续进步、杀手级应用的出现、易用平台的开发,以及最终用户的行为和偏好。
        </p>

        <blockquote>
          从目前的发展趋势看,我们可能正在接近一个转折点。无论在学术界还是工业界,能力提升的速度都明显加快了。
        </blockquote>

        <p class="con">
          虽然具体会以什么形态出现、何时出现还不确定,但多条技术路线的汇聚,都指向一个比人们通常预期更近的未来。这是一个充满可能性的时刻,各个部分正在快速拼合到一起。问题或许不是3D通信会不会成为主流,而是我们能否及时察觉这个转变何时开始发生。
        </p>

        <!-- Your content ends here -->
      </div>

            <!-- Author Info Section -->
      <div class="author-info">
        <h3>关于作者</h3>
        <p>
          <strong>斐然</strong> 是一名计算机视觉方向的博士生,
          研究专注于3D重建、视觉基础模型、医学影像和生成式AI。
        </p>
        <p>
          <a href="../index.html">访问我的主页</a> 了解更多研究和论文。
        </p>
      </div>

      <!-- References Section -->
      <div class="references">
        <h3>参考文献</h3>
        <ol>
          <li>Schönberger, Johannes Lutz, and Jan-Michael Frahm. "Structure-from-Motion Revisited." <em>Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2016.</li>
          <li>Newcombe, Richard A., et al. "Kinectfusion: Real-time dense surface mapping and tracking." <em>2011 10th IEEE international symposium on mixed and augmented reality</em>. IEEE, 2011.</li>
          <li>Yao, Yao, et al. "Mvsnet: Depth inference for unstructured multi-view stereo." <em>Proceedings of the European conference on computer vision (ECCV)</em>. 2018.</li>
          <li>Mildenhall, Ben, et al. "Nerf: Representing scenes as neural radiance fields for view synthesis." <em>Communications of the ACM</em> 65.1 (2021): 99-106.</li>
          <li>Kerbl, Bernhard, et al. "3D Gaussian splatting for real-time radiance field rendering." <em>ACM Trans. Graph.</em> 42.4 (2023): 139-1.</li>
          <li>Wang, Shuzhe, et al. "Dust3r: Geometric 3d vision made easy." <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 2024.</li>
          <li>Wang, Jianyuan, et al. "Vggt: Visual geometry grounded transformer." <em>Proceedings of the Computer Vision and Pattern Recognition Conference</em>. 2025.</li>
        </ol>
      </div>



      <div class="blog-footer">
        <p>&copy; 2025 Feiran Wang</p>
        <p style="margin-top: 15px; font-size: 13px; color: #aaa;">
          本文使用 <a href="https://claude.ai" style="color: #1772d0; text-decoration: none;">Claude</a> 进行文字修饰与翻译。
        </p>
      </div>
    </div>
  </body>

</html>
